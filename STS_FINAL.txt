STS 201
Technology & Society Case Study
15 Dec. 2020


A-1
My sociology textbook Race in America by Matthew Desmond and Mustafa Emirbayer gives the impression that it could fit under a variety of different methods of knowledge production, but the method that wins out has to be logical positivism. Truly, I feel that logical positivism is a very appropriate, even essential, way of teaching sociology at this level predominantly because of its structured approach. Logical positivism is all about the steady accumulation of knowledge which continually builds and strengthens the base upon which scientific theories can be created, and when I look at my sociology textbook, I see a very similar structure. After an initial chapter that reminds the audience of the state of race relations here in the 21st century, the authors turn back the clock to “The Invention of Race”. From there, they work their way forward in time, dedicating each chapter to an aspect of the amazingly complex relationship the United States holds with its minority citizens (or non-citizens, for that matter). Whether it be a discussion on politics, economics, housing, or crime and punishment, each chapter acts as a building block in the formulation of an enhanced race-conscientiousness in the reader. In the final chapter, “Toward Racial Democracy”, the authors offer several responses to racial inequality moving forward. They do not ultimately make a claim as to what exactly we need to do as a society to fix our race problem once and for all, but, by taking into account all that we have learned so far, they are able to at least make some highly-educated suggestions. I believe that this style is very effective with undergrads because, frankly, it is the kind of learning that we are most likely to be familiar with. I know that in my experience, learning has always been a matter of building; first there was reading which led to writing which led to math which led to an explosion through the years of grade school of discovering and internalizing different topics and techniques, the sum of which creating the complete student that I am today. Logical positivism is natural, or at least it has been made so. However, logical positivism is not perfect. For example, the basis of theories rooted in logical positivism rest upon the assumption that the facts constituting those theories are all true. If, later on, there are found to be flaws within the sociology textbook, the reliability of the entire work must come into question; if the knowledge is flawed in one area, who knows how far the influence of that flaw reaches, how many other “facts” have ties to what is now fiction? Now, this is certainly not to say that, if something in this textbook were to be disproved, the notion that racism is a problem would come into question. Rather, it would suggest that perhaps there exists a remedy that we’re not seeing or an action that we’re not taking that we otherwise might have explored had we been in possession of the “correct” knowledge all along. Regardless, for the time being, this textbook is an excellent example of logical positivism in action. 


Logical positivism is far from the only way to do science and knowledge out there, and it may not even be the only way to learn sociology! Other methods include falsificationism, functionalism, Kuhnian, and realism. Falsificationism puts the emphasis on testability, specifically the ability to prove something wrong. The main idea is that we cannot definitively prove something, but we can definitively disprove something. That said, the Duhem-Quine thesis, stating that theories cannot be conclusively tested in isolation, shows that “proving something wrong” may simply be a result of a bad measurement or an incorrect interpretation, among other possibilities. Functionalism is the idea that our society can be thought of as a collection of institutions, each serving a particular purpose. In addition, these institutions each have a structure that maintains them; for science, it is the Mertonian Norms. The norms explain how science in general should be conducted in order to produce the most reliable results, but the fact remains that science is an enormous and diverse institution, if it is to be considered a singular institution. The norms could end up being perceived as acting upon different fields of science unequally or becoming too flexible in attempting to encompass everything, thus damaging their own credibility. Kuhnian science explains how the conduction of knowledge and science evolves over time. Basically, scientists do science within the confines of a paradigm, or a commonly held set of knowledge on how things work. However, that knowledge is not absolute; time and time again, history has presented scientists with anomalies contradicting their beliefs, and if enough anomalies build up, the scientific community goes into crisis mode. This is what is considered a paradigm shift; scientists essentially have to build a new foundation for their science taking into consideration the newest findings, and the end result is a new paradigm in which there exists an updated commonly held set of knowledge on how things work, or at least it becomes commonly held once the old guard of thinkers entrenched in the previous paradigm pass on, leaving the reins of science to the next generation. Finally, realism is the idea that anything at all can be considered science provided it guides us closer to the truth. Unfortunately, there isn’t actually a way to know if the ultimate truth has been reached, and in the absence of that ability, there isn’t a way to know how far away it is or even if we’re moving in the correct direction. That said, our sociology textbook could definitely be rewritten using realism as the main method of distributing knowledge. In that reality, our textbook would replace structured commentary with sections designed purely to enhance our knowledge of race and its implications, regardless of the format. There could be primary source documents such as copies of old newspapers or studies, there could be picture collections or graphic novels, or there could even be interactive activities that the authors would have us do in the real world. Anything and everything is on the table so long as it works towards strengthening our knowledge and understanding. That said, the textbook would still lack a true answer to the race problem; digesting old documents and deciphering old pictures might not show us exactly what we need to do, but doing so would indeed succeed in making us more aware of where we came from and where we’re going, and what else would be the focus of any text taking on race if not to do just that?
________________
B-4
Anyone can be considered a lay expert who has developed, adapted, or perfected some understanding of a technology or practice to the point where they can be reasonably said to have expertise on it, provided they are listened to or even acknowledged in the first place. Either case can describe someone who has extensive knowledge on something, but the primary difference between lay experts and traditional experts is formal training on the subject, or lack thereof. To many people, especially traditional experts, this status is basically the end-all be-all. In other words, lay experts are not often given credit for what they have to offer because expertise is typically passed off from one “true” expert to another by way of a sheet of paper saying they graduated with this degree from that institution. However, this does not by any stretch of the imagination mean that “formal scientists” working in a lab are always unequivocally better at conducting reputable science than informal scientists who happen to work in their home. If anything, even though they may not possess the same financial firepower, lay experts on a particular subject may have had more flexibility to delve deeply into it than did a traditional expert. Lay experts aren’t bound by the rules and regulations of scientific bureaucracy; they are allowed to keep their agency, to cut loose and solve whatever problem they so desire. This capability has given rise to a number of truly good inventions, not the least of which being Lorenzo’s Oil, a treatment for kids with ALD created by a regular family. Being that ALD is such a rare disease, little to no medical research was dedicated at the time to it; lay expertise proved to be a way to help real people with real problems, albeit less common ones. This is where tacit knowledge comes into play: the more individualistic the issue, the less likely it is to be worked with or even documented. Tacit knowledge has to do with the things people know that have more or less become a part of them; in essence, it is the difference between a technique or practice one knows because it has been in their family and tinkered with for generations and the education one receives from 4-6 years in a post-secondary school. On the one hand, the lay expert’s knowledge may be beyond extensive in whatever it is that they are working on, but that knowledge may or may not be very applicable outside of its immediate context. On the other hand, a student fresh out of college may have knowledge to help the masses, but are not the lives of the few just as important as the lives of the many? It is a fine line science must walk, but it shows that lay expertise absolutely has its place. 


As stark a contrast as lay experts compared to traditional experts may present, in the real world, true expertise is really measured more on a gradient scale. For instance, one might interact with experts regularly enough to be able to “speak their language”, so to say; they are able to talk the talk of an expert, but they still lack the actual skills to walk the walk. This is an example of what may be called interactional expertise. The bottom line for the interactional model is simply the more one is able to give back to a field, whether they are making active contributions compared to just being able to talk it up or being the one people go to for help instead of being the one asking, the greater expertise they are considered to have. For example, I feel like UW-Madison students currently finishing STS 201 can now be considered interactional experts in Science and Technology Studies. Over the course of the semester, we have learned enough to become conversational in a variety of relevant STS topics, but, at the same time, the vast majority of us are far from ready to head on out and begin conducting real STS research. This idea is similar to the relational model of expertise, which states that in order to be considered an expert, we need to be able to both act as would an expert and be seen by others as would an expert. While we may have a capacity to understand some of what an STS expert is saying, we would almost certainly be laughed at if, as Professor Hayes so eloquently put it, stood up and said “I am an expert!”
________________
C-8
The gender disparities across STEM fields have come a long way over the years, but they nevertheless are still very much real. Professor Hayes shared with us a graphic in his lecture entitled “Science & Technology & Inequality” that depicted that, with the exception of the social sciences, women constitute a minority in all of the major STEM fields, and they sit at a destitute overall average of less than 30%. Granted, this is still an improvement from the 1970’s when no STEM profession saw a female representation of more than 20%, but there is still plenty of work to be done. For example, even for the women who find their way into STEM and conduct strong research, they are often automatically disadvantaged by way of academic citations, or relative lack thereof. Another graphic in the same slide of the lecture shows how basically, no matter what, women are less likely to be cited when in a lead role for study than are men. There is no evidence suggesting that the work put out by women is any less reliable or thorough than work put out by men, so it just goes to show that the fight isn’t just to get women into science but to make sure that once they are there, they receive a level playing field. A level playing field, however, is not limited to equality in recognition; statistics show that on top of everything else women in STEM have to deal with, they undergo discrimination in the workplace across the board in relation to their male counterparts. Whether it be through how much they are undercompensated, how often they are underestimated, or how little they are supported, it is a marvel that women are doing as well as they are and continuing to grow in STEM despite the deck being stacked against them. 


Digging a little deeper, the very concept of gender can be seen to be a scientific construction in the first place. This is not to say that before a certain date, every human being was seen as being the same (no gender recognition), but the theory of gender did eventually become a scientific reality. At first, when researchers were searching for what caused the differences between men and women, they settled on what was known as the Metabolic Theory, that during their development, fetuses could end up as either male or female, and the state of the fetus’ gender could fluctuate in response to external stimuli such as temperature. However, with the advancement of microscope technology came the discovery of chromosomes which has since dominated the fundamental perception of gender. The chromosome-based theory boiled gender down to a very simple matter of the difference in one chromosome: one either has an XX or an XY, as each combination appeared to endow the individual with certain characteristics that we perceive as being male and female. In short, a binary has been created based on the condition of one microscopic chromosome, whether it has one arrangement or the other. However, even more recent research has shown that it really isn’t so clear-cut anymore. Sure, the vast majority of people are born with either XX or XY, but there are other factors that go into what makes a person believe that they are truly a male or female. Physical characteristics aside, everyone is not predisposed with a consistent level of certain hormones or other bodily chemicals; in fact, such levels are much more accurately described as being on a spectrum, with no two people despite their apparent gender, having exactly the same. Moreover, while there may be a tendency towards one end of the spectrum versus the other based upon one's “birth gender”, it is by no means absolute. More and more, we are finding that people born into one gender based solely upon how one chromosome causes them to look are discovering that they really do not belong there, and I believe that it goes to show that the common conception of a binary-based gender system perhaps, in the coming years, will need to, yet again, be re-examined.


Interestingly enough, science itself, an entity that would seem to be completely neutral and unbiased, often enough can be gendered too. Most commonly, this comes in the way that certain things are described in relation to whether they are more associated with, in the binary model, one gender or the other. For example, our class viewed a clip from a video called The Miracle of Life that takes the audience through the journey both male and female sex cells take in pursuit of fertilization and the creation of life. However, the processes were certainly not equal. On the male side, fertilization is depicted as predominantly active, a perilous competition among millions without even a guarantee that any will survive. On the female side, fertilization is depicted as passive, a slow, days-long journey for the egg as it is peaceably guided along until the point where it is either fertilized, or it is not. The distinctions may be subtle, but they are present nonetheless. Such distinctions can be extended outside of reproduction as well, indeed to a wide variety of scientific concepts. Human brains and behaviors are delineated as being a male or a female brain, male or female behaviors; even in nature, with lifeforms that in no way resemble the physical characteristics we associate with gender in humans, we ascribe as having male or female traits. But what is to say that humans even have the concept of gender right in the first place, let alone that we have the authority to attribute gender to a nonhuman?


For all of its glamour and benefits to society, technology over time has allowed for the subjugation of women to really flourish. For example, advancements in medical instruments have given male doctors the authority to know more about women’s bodies than they do themselves. In the absence of a sufficient percentage of female doctors, this development gave men the opportunity to continue to dominate the field without too much in the way of obstruction. Beyond health, technological advances gave way to men being able to control the narrative for society and reinforce their vision of gender roles. Certain products were often marketed towards an intended audience of either men or women, and Professor Hayes’ lecture “Science & Technology & Inequality” again provides some excellent examples. Namely, ads for household cleaning and cooking technologies often featured women while ads for computer and entertainment technologies featured men. Little known is that as far back as the 70s, computer science had fairly equal representation between men and women (per Hayes’ lecture). Most people do not know that though, and that is because female contributions to computer science, and STEM in general, have been black boxed in favor of glorifying the contributions of males: most people have heard about Steve Jobs and the creation of Apple but not necessarily about Ada Lovelace and the foundation for computing itself. That said, it has been through the systematic targeting of advertisements over the decades that computer science especially has come to nowadays be dominated by males.


Once one is made known of them, the principles of feminist STS are hard to miss in everyday life, even in as commonplace an occurrence as going to the doctor. For starters, through the systematic application of bias and discrimination that exists in the health field, in education, training, and practice, the same way as in any other field, one is likely to be admitted by a female nurse who eventually gives way to a male doctor. This is not always the case, and it is improving, but it is the most likely scenario, and it is because of the field, for as long as anyone can remember, being highly gendered. Being a doctor is made out to be a great challenge involving a lot of time away from loved ones and family life, which caters much more to what society would expect a male would be willing to undertake. At the same time, the nurse position provides an opportunity to act as a sort of secondary to doctors, not having to go through as strenuous a route to get there and having more time for family, thus catering more to what society would expect a woman to undertake. Once one is inside, they are most likely to be treated as a male or as a female. Simply put, certain practices and procedures are designed to be administered only to males or only to females, regardless of where they feel they stand personally. Additionally, even practices applied to both males and females are not applied equally. In my personal experience, when I go to the doctor’s office with my sister to get a flu shot, it is more or less assumed that I am fine with everything, whereas they take extra little measures with her, such as a shot blocker to mask the poke and extra dialogue regarding whether or not she is handling it okay. I have a feeling that such is the way with more than my sister and I, that there is a subtle divide in how men are treated compared to women, and that, like everything else, goes back to perpetuate the stereotypes and patterns that we as a society are wrestling with to defeat to this day. 
________________


D-10
Alongside all of the glorious developments in science and technology over the years has been, unfortunately, a rise in what is known as the Risk Society. The Risk Society, similar to Newton’s Third Law, is the idea that such technological developments often, at the same time, either intensify existing risks that people have to deal with or create new ones altogether. The kicker, though, is that the boom in risks is not affecting everyone equally, hence the “society” part of Risk Society. In short, the amount of risk an individual takes on in their life from day to day has a very strong correlation to their position in regular society. Working class citizens are predisposed to multitudes of risks that really don’t affect those in the upper classes. For example, working class citizens are less likely to have completed some form of higher education, so they are relegated to jobs that involve a greater deal of risk, particularly manual labor and factory jobs involving dangerous chemicals and machinery. Furthermore, even once they are home from their jobs, lower class citizens are more likely to live in areas with poor land values, especially areas with a higher likelihood of pollution or crime. By this model, it is much easier to understand some of the intricacies that go into the phrase “the rich get richer”; not only is the wealth trickling upwards in society but the risks are trickling downwards. 


While the Risk Society lays the foundation for who in our society are more likely to be exposed to risk on a day-to-day basis, the Social Amplification of Risk Framework (SARF) details how risks are communicated throughout society and acted upon according to their threat levels. At its core, SARF begins with an event that is out of the ordinary. As people within the vicinity of the event begin to identify what’s going on and how big a deal it is, they make a judgement call as to whether or not it is even worth worrying about. If it is something they feel people need to hear about in a timely manner, they collect whatever information they deem most important and get it out to the public. At that point, different people and groups may react differently to the news, but the endgame is to get the information into the hands of people with influence. Once that is achieved, a chain reaction will occur among those who hold increasing levels of influence over the area affected by the event, and until the sphere of influence grows to the point where the risk factor becomes insignificant, each will exercise their power to recommend a course of action, which could be anything from “do nothing” to “evacuate immediately”. Ultimately, the powers that be over a given area will take whatever action they deem necessary, and whatever the choice may be will impact society within those bounds. People will either react positively or negatively, and that reaction will inform how society reacts to events in the future and who they trust to make the right calls on what to do at that point. 


The formation of risks and risk management can also be seen as being dependent on the type of society within which they are found. In the Cultural Theory of Risk, Mary Douglas demarcates four quadrants a certain society can be found in based essentially on its distribution of power and allowance of individuality. For societies of a Hierarchist culture, one in which the society is very structured and a high amount of control is exerted on the population overall, the management of risk is just held by those with power, expertise, or both to do whatever they feel is best. In an Egalitarian culture, the general control over everyone remains, but the structure of the society is removed in favor of everyone being equal; risk management here would aim at everyone being exposed to as close to equal amounts of risk as possible. Individualist culture exhibits a hands-off approach where everyone is given equal opportunity, but they are then left to assess and deal with risk for themselves. And finally, a fatalist culture is one where the people are locked into their place within society but are not really given any support to manage risk, regardless of where they are. This results in people not really even caring about managing risk, not as much because they don’t want to but because they feel that they are isolated and incapable of doing anything about it. Each of these varieties of risk management shape the attitudes and thought processes of the people living within a given society, which makes them self-reinforcing pending a major shift in power or policy. 


The whole purpose of risk is to be an assessment of the probability of an accident occurring. There are several categories of accidents, but the most common one is the aptly-named normal accident. The premise of normal accidents is that no matter what the system is that is in place, something wrong is bound to happen over enough time. Also, for an accident to be considered a normal accident, it must meet four criteria, which are laid out in Professor Hayes’ lecture slides from the first day of week ten. First, normal accidents exhibit warning signs that are only interpreted as warning signs after the fact. Second, the system in question must have multiple instances of design failures or equipment malfunctions. Third, whoever was in charge of the system when it went awry made some error in operation or judgement. And fourth, the origin of the accident must have spread carnage to other parts of the system, generating a “negative synergy” that makes the accident much worse than simply the first problem. Normal accidents are different from unique and discrete accidents in that unique accidents are so rare that they are not worth preparing for, and discrete accidents are so minor that they can be easily fixed anyway. Possibly the biggest difference is the presence of agency when it comes to normal accidents; in order for a normal accident to occur, someone has to consciously take on that risk. Sometimes, though, the risk can be catastrophic. For example, with the Challenger explosion, there were warning signs all along that the O-ring in question was susceptible to failure. Despite knowing that fact, the operators continued to launch the Challenger in very cold conditions which only exacerbated the O-ring’s issues. And finally, the O-ring failing created a chain reaction that blew up the entire spacecraft; one little malfunction created a very large problem. Another notable example is Chernobyl. At Chernobyl, there were plenty of warning signs that something was very wrong, not the least of which being a large explosion followed by high levels of radiation. Not only had the core blown up in the first place, but the control center was not conveying that there was anything especially wrong. This led to the Chernobyl authorities and indeed the Communist authorities to write off the issue as being minor and to take little to no emergency action outside of trying to put out the fire. In the end, a bad valve led to the worst nuclear meltdown the world has ever seen. Yet another example of a normal accident was the Bhopal disaster. Before the situation got out of control, there was an identified leak in one of the chemical tanks at the Union Carbide facility, but it was just assumed at the time to be water, so they didn’t give it much thought. Later on, it was discovered that there were a number of issues, especially the dysfunctional leaky pipe but also that the instruments were thought to be unreliable, so they weren’t given much stock when they went crazy that time. A human hand had a major role in the disaster, as an under-qualified worker was asked to clean the very pipe that would end up the root of the accident, and as a result of that pipe being messed up, a leak started that created a reaction in a storage tank that resulted in the release of toxic gas that killed over 15,000 people. 
________________
E-12
The Actor Network Theory (ANT) is the idea that nothing exists or persists independently. Rather, every person, every tool, every technology, everything is a part of a grand network that binds together our reality. This network is constantly growing and evolving and is built upon the relationships between actors and actants. “Actor” and “actant”, however, are simply relative terms; it boils down to what is influencing what when. For example, if, while I’m at work, someone’s computer stops working properly, that computer becomes an actor when it compels me to go and fix it. That said, once I begin working on the computer, the relationship flips; I am now the actor performing on and influencing the behavior of the computer. At any given time, that which is acting is the actor, and that which is being acted upon is the actant. By extension, all of the actions and interactions in our world, big and small, can be seen to be a product of these fluctuating relationships. To clarify, the ANT implies that we as humans are not above the technology we use, and neither is the technology we use above us. Humans would not have been able to reach the heights that they have without technology, but technology itself as we know it would not have come into being had it not been for humans. All along the way, it has been the interactions between humans and nonhumans that have fueled one another’s development, and it is the accumulation of these interactions that has constructed the very reality that we see and exist as a part of today. Additionally, it is important to note that as this network has expanded, nonhumans have begun to interact with each other more in place of strictly human-nonhuman encounters. Such occurrences are tied to the growing complexity of the systems we humans employ; in essence, nonhuman labor is gradually replacing human labor through a process of what Bruno Latour calls “congealed labor”. Basically, congealed labor is the idea that everything constituting the technologies humans use, from pencils to spacecraft, originated as purely human labor. That labor eventually was put into creating tools which were used to create machines to create better tools and better machines in a constant cycle. In the end, everything would seem to be a part of one great machine, humans and nonhumans alike acting as components, working together to run the machine that is society and ultimately reality itself.


There have indeed been countless examples of how our relationships with technologies of all varieties have been beneficial, but even the simplest of technologies, if enacted in a certain way, can also have historically adverse effects. Regular signs ringing the infamous “sundown towns” of the late 1800s and early 1900s are an example of how simple socio-technological forces could create and perpetuate belief systems within neighbors and even entire cities. Such signs would typically state in plain terms that racial minorities were not allowed after sunset, and they effectively worked to facilitate a racially exclusive territory. Indeed, any instance through the years of a sign warding off racial minorities simultaneously operated within the ANT framework, modifying those living within the community as well as those left out; the whites engaging in such behavior were self-validated by their dominance remaining intact, and the nonwhites were left to an even stronger sense of dejection. Importantly, the signs replaced immediate violence with the threat of violence; the signs were able to create the same atmosphere within the town or neighborhood of who belonged and who didn’t without the actual white humans having to do as much work, as horrible as that sounds. Furthermore, during when such signs were legal, they were effective without the white people putting them up having to rely on higher forces such as land values or public institutions to keep their areas, as their thinking went, safe. Despite minority citizens beginning to become financially capable of living among whites, they were not welcomed, and “whites only” signs played a major role in maintaining that status. 


One of the major challenges to the ANT is over agency; if all things are on equal ground, humans and nonhumans alike, to what extent are nonhumans really able to exercise their agency? For that matter, are humans even able to exercise agency themselves? Agency in the ANT appears to become solely reliant on the relationships between actors as opposed to the actors themselves. For example, when someone goes to hammer in a nail, do they use a hammer of their own volition, or are they compelled to by the facts that the nail isn’t going to hammer itself and that not using a hammering device would result in a rather painful endeavor? Agency then effectively becomes a mirage concealing what are actually predetermined events. And then, if we actors are to actually maintain our agency, that agency cannot really be said to be evenly distributed. For example, components within a pencil sharpener may act and be acted upon by one another, but what real choice do they have? They are really only able to do what they were designed to do or fail trying; despite them being actors that may even be acting upon humans in the event that the shavings container fills up or the power supply runs out of power, the agency still ultimately rests with humans.